



%Al fine di valutare se la scelta della tecnologia SiC-CsI può soddisfare le esigenze di NUMEN è stata implementata una simulazione Monte Carlo sulla piattaforma GEANT4.
%In questo capitolo vengono esposte le principali assunzioni e vengono presentati i risultati.



Nei moderni esperimenti di fisica l'importanza delle simulazioni computerizzate è andata via via crescendo grazie all'eccezionale sviluppo dei computer e dei software volti a tale scopo; in particolare, l'introduzione delle tecniche Monte Carlo si è rivelata un potente strumento per trattare problemi complessi altrimenti difficilmente risolubili.
In questo capitolo, dopo aver descritto le principali caratteristiche dei metodi Monte Carlo, si discute brevemente della piattaforma \geant, con cui sono state implementate le simulazioni svolte per questo lavoro di tesi (\textcolor{red}{Geant4 va scritto così?}).

%Successivamente, vengono presentati gli aspetti più importanti di tali simulazioni, le quali avevano lo scopo di valutare se la scelta di utilizzare dei telescopi basati sulla tecnologia SiC-CsI può soddisfare le esigenze di NUMEN.
Successivamente, dopo aver presentato gli aspetti più importanti di tali simulazioni, vengono discussi i risultati ottenuti, illustrando nei diversi casi le matrici $\Delta E - E$ e calcolando la percentuale di errore nell'identificazione degli ioni simulati.




%Le simulazioni giocano un ruolo fondamentale nella fisica.

%In fisica, come in altre scienze, le simulazioni giocano un ruolo fondamentale, in quanto permettono di studiare la risposta di sistemi complessi tenendo sotto controllo alcuni dei suoi gradi di libertà.

\section{\iflanguage{italian}{Le simulazioni computerizzate e i metodi Monte Carlo}{Computer simulations and Monte-Carlo methods}}


In fisica, come in altre scienze, le simulazioni computerizzate giocano un ruolo fondamentale, in quanto permettono di affrontare lo studio di sistemi che sarebbero difficilmente trattabili utilizzando tecniche teoriche o sperimentali~``classiche'';
spesso, infatti, tali approcci possono presentare problematicità legate alla complessità del sistema, al tempo necessario per lo sviluppo e l'analisi, ai costi per la realizzazione di prototipi.
Introdotte negli anni Trenta grazie all'apporto di prestigiosi scienziati come von Neumann, Ulam e Fermi, il loro progresso è stato parallelo a quello dei computer, arrivando oggi ad essere uno strumento imprescindibile in molti esperimenti.
Esse forniscono una diversa prospettiva con cui guardare alla realtà, diventando in alcuni casi una base teorica da cui partire per l'interpretazione dei risultati sperimentali, oppure in altre situazioni producendo dati ``sperimentali'' con cui mettere al vaglio le teorie.


Tra i diversi metodi di simulazione computerizzata, particolare importanza hanno assunto i cosiddetti \emph{metodi Monte Carlo}~\cite{metropolis:jasa49}, il cui nome fu coniato da Metropolis ispirandosi al casinò omonimo.
%Tali metodi utilizzano la generazione di sequenze di numeri \emph{pseudo-casuali} per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà, 
%laddove i numeri pseudo-casuali sono dei numeri prodotti in modo deterministico ma con proprietà statistiche simili a quelle dei numeri casuali.
%
Il numero di problemi che al giorno d'oggi vengono studiati utilizzando questa tecnica è enorme, annoverando campi di ricerca estremamente diversi, che vanno dalla fisica nucleare alla fisica medica, dalla meccanica statistica alla sociofisica, dall'economia alla biologia.
%Darne una definizione comprensiva di tutte le aree di interesse è un compito difficile e sostanzialmente inutile.
%
% ***** QUESTO NON ERA MALE
%Sebbene darne una definizione comprensiva di tutte le aree di interesse sia un compito difficile, in generale è possibile dire che i metodi Monte Carlo utilizzano la generazione di numeri casuali per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà accoppiati.
%
%
Sebbene darne una definizione comprensiva di tutte le aree di interesse sia un compito difficile, in generale è possibile dire che i metodi Monte Carlo sono dei metodi numerici di risoluzione di equazioni o di calcolo di integrali basati sulla generazione di numeri casuali.
%I metodi Monte Carlo utilizzano la generazione di numeri casuali per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà.
Il generico metodo si compone principalmente di quattro fasi:
\begin{itemize}
	\item generazione di una sequenza di numeri casuali;
	\item calcolo delle variabili di input sulla base della sequenza estratta;
	\item determinazione delle variabili di output utilizzando le variabili di input calcolate;
	\item ripetizione dei punti precedenti e analisi critica dei risultati.
\end{itemize}



%Dal momento che i metodi Monte Carlo dipendono fortemente dalla produzione veloce ed efficiente di flussi di numeri casuali, si preferisce generare le sequenze di numeri via software, piuttosto che leggerli da tavole ad hoc.
%Tuttavia, poiché tali algoritmi sono, in realtà, deterministici, 
%In realtà, dal momento che, per ragioni di velocità ed efficienza, tali sequenze sono prodotte via software, i numeri sono \emph{pseudo-casuali}
%Per risolvere un problema complesso è necessaria una sequenza molto grande di numeri casuali, i quali devono essere indipendenti fra loro.
Affinché il metodo si dimostri efficace, è essenziale che la sequenza di numeri sia quanto più possibile casuale.
Dunque, proprio la casualità con cui vengono prodotti tali numeri rappresenta il punto più delicato del metodo e, forse, il suo limite più grande; infatti, per ragioni di velocità ed efficienza i numeri vengono generati via software, invece di basarsi su processi fisici realmente casuali.
%Tuttavia, dal momento che tali algoritmi sono inevitabilmente deterministici, le sequenze di numeri sono, in realtà, \emph{pseudo-casuali}, ovvero presentano delle proprietà statistiche simili a quelle dei numeri casuali. 
Tuttavia, dal momento che tali algoritmi sono inevitabilmente deterministici, ogni numero della sequenza è univocamente calcolato a partire dal suo predecessore. 
Quindi, le sequenze di numeri sono, in realtà, \emph{pseudo-casuali}, ovvero presentano delle proprietà statistiche analoghe a quelle delle sequenze di numeri casuali, ma sono prodotte in modo deterministico. 
Per questo motivo, una successione di numeri pseudo-casuali non può avere elementi infinitamente diversi, in quanto, prima o poi, cominceranno a ripetersi.

Negli ultimi trent'anni l'importanza delle simulazioni basate su metodi Monte Carlo è cresciuta senza soluzione di continuità. 
%Uno dei motivi di tale successo deriva in quanto al crescere della complessità del problema tale tecnica risulta superiore rispetto agli approcci analitici in termini di tempo necessario per la 
%Uno dei motivi di tale successo deriva dalla maggiore efficacia di queste tecniche rispetto agli approcci analitici nella risoluzione di problemi caratterizzati da alta complessità;
%ad esempio, valutando l'efficacia di un metodo in termini del tempo necessario per risolvere un problema, al crescere della complessità risulta che tale tempo cresce più lentamente per i metodi Monte Carlo in confronto ai metodi analitici.
%come illustrato in Figura~\ref{fig:monte_carlo}, il tempo necessario 
%Uno dei motivi di tale successo deriva dalla grande efficacia di queste tecniche nella risoluzione di problemi altamente complessi;
Una delle ragioni di tale successo deriva dalla grande efficacia di queste tecniche nell'affrontare lo studio di sistemi con un numero elevato di gradi di libertà accoppiati; 
ad esempio, è possibile dimostrare che, al crescere della complessità del problema, i metodi Monte Carlo richiedono meno tempo per giungere alla soluzione rispetto alle tecniche analitiche o deterministiche, come mostrato in Figura~\ref{fig:monte_carlo}.


\begin{figure} [!t]
	\centering
	\includegraphics[scale=0.75]{Grafici/monte_carlo_vs_analytic2.png}
	\caption{Confronto fra il tempo necessario per la risoluzione di un problema con un metodo analitico-deterministico e con un metodo Monte Carlo, al variare della complessità del problema.} \label{fig:monte_carlo}
\end{figure}


%Nel campo della fisica, i metodi Monte Carlo sono spesso utilizzati per 
%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui l'elevata complessità degli apparati di rivelazione necessitava di uno strumento per decidere le specifiche in fase di progettazione.


%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui la crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
%
% ***** PRIMA AVEVO MESSO QUESTA
%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui si comprese che tali metodi offrivano la possibilità di seguire la traccia delle particelle e simulare le loro interazioni con la materia.
%
Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui si comprese che tali metodi, offrendo la possibilità di seguire la traccia delle particelle e simulare le loro interazioni con la materia, potevano essere impiegati sia per la progettazione dei rivelatori sia per lo studio della loro risposta nelle condizioni sperimentali di interesse.
In questo contesto nacque il codice \emph{GEANT}, di cui nella sezione successiva si espongono le principali caratteristiche.





%\section{\iflanguage{italian}{La piattaforma \textsc{Geant4}}{\textsc{Geant4} toolkit}}

\section{\iflanguage{italian}{La piattaforma Geant4}{Geant4 toolkit}}

%\section{\textsc{Geant4}}

La piattaforma GEANT, il cui nome deriva da \emph{GEometry ANd Tracking}, fu sviluppata nel 1974 al CERN di Ginevra allo scopo di simulare l'interazione di particelle elementari ad alta energia con i rivelatori.
%Questa prima versione consentiva di simulare il trasporto di un numero ristretto di particelle 
%In questa prima versione era possibile simulare soltanto un numero ristretto di particelle
In questa prima versione era possibile considerare soltanto un numero ristretto di particelle e forme geometriche semplici. 
Nel 1982 venne distribuito GEANT3, scritto in FORTRAN e nettamente potenziato rispetto al suo predecessore; infatti, si potevano simulare apparati sperimentali grandi e sofisticati e fasci di particelle molto intensi ed energetici.
Tuttavia, il codice presentava una struttura molto complessa, che rendeva difficile l'introduzione di nuove caratteristiche o la ricerca di errori.
%the simulation software geant4, which means \emph{geometry and tracking}, is a toolkit based on
%Fu così che si arrivò al 1998, anno dell'uscita dell'ultima versione del codice, chiamata \geant, interamente basata sul linguaggio C++.
%La crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
%
%%Fu così che nel 1998, grazie alla collaborazione di oltre 40 istituti internazionali, venne pubblicata l'ultima versione del codice, chiamata \geant.
D'altro canto, la crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
Fu così che nel 1998, grazie alla collaborazione di oltre 40~istituti internazionali, venne pubblicata l'ultima versione del codice, chiamata \geant.
Essa è interamente basata sul linguaggio C++, traendo vantaggio, dunque, da tutte le potenzialità offerte da una tecnologia orientata agli oggetti, come ad esempio la modularità e la compattezza.
% oppure il polimorfismo
%Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto comprende un insieme di librerie software che l'utente può selezionare a seconda delle proprie esigenze per creare un'applicazione specifica.

Oggi \geant{} consente di simulare l'interazione con la materia di tutte le particelle note, in un range energetico che va da pochi~eV fino ai~TeV.
%
%La sua notevole duttilità lo ha reso uno strumento 
Grazie alla sua notevole duttilità, sono innumerevoli gli esperimenti che si avvalgono di questo strumento e la sua area d'applicazione va dalla fisica delle alte energie, agli studi nucleari, alle applicazioni in campo medico, all'astrofisica.
Il codice è, inoltre, open-source e viene periodicamente aggiornato dalla collaborazione. 
Dal momento che la documentazione su \geant{} è ampia e dettagliata\footnote{Si veda, ad esempio, \url{www.geant4.cern.ch}}, nel prosieguo vengono presentati soltanto gli aspetti utili alla comprensione della simulazione svolta per questo lavoro di tesi.  



%\subsection{\iflanguage{italian}{La struttura di \textsc{Geant4}}{\textsc{Geant4} structure}}

\subsection{\iflanguage{italian}{La struttura di Geant4}{Geant4 structure}}

%Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto comprende un insieme di librerie software che l'utente può selezionare a seconda delle proprie esigenze per creare un'applicazione specifica.
Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto è costituito da un insieme di librerie software che, a seconda delle esigenze, possono essere selezionate per creare un'applicazione specifica.
L'utente deve, quindi, scrivere la sua applicazione, definendo tutti i parametri rilevanti: alcuni devono essere inseriti in modo obbligatorio, altri possono essere aggiunti facoltativamente.
%\geant{} offre numerose funzionalità:

%Ogni simulazione si compone dei seguenti aspetti: 
Nella progettazione e nella realizzazione del software, tutti gli aspetti fondamentali di un processo di simulazione sono stati inclusi:
\begin{itemize}
	\item la geometria del sistema, specificando forma, dimensione e posizione dei vari oggetti;
	\item i materiali utilizzati;
	\item la sorgente delle particelle, di cui si definisce la posizione, l'energia, la distribuzione angolare e tutte le altre caratteristiche rilevanti;
	\item i processi fisici di interazione per la modellizzazione  del comportamento delle particelle;
	%\item il tracciamento delle particelle, che può essere calcolato anche passo dopo passo, consentendo di estrarre ad ogni step informazioni legate alla particella, come ad esempio energia e posizione;
	\item il tracciamento delle particelle attraverso materiali ed, eventualmente, campi elettromagnetici esterni;
	%\item la sensitività di un rivelatore e la sua risposta;
	\item la definizione di elementi sensibili, che simulano la risposta del rivelatore;
	\item la visualizzazione tridimensionale degli oggetti simulati e delle tracce delle particelle;
	\item la generazione di dati, i quali possono essere memorizzati per una successiva analisi.
\end{itemize}


%Ciascuno degli aspetti elencati corrisponde ad una determinata \emph{classe} o \emph{categoria}, che, agendo in modo indipendente l'una dall'altra, danno al software una struttura modulare.

Gli aspetti elencati corrispondono in \geant{} a determinate \emph{classi} o \emph{categorie}, che, agendo in modo indipendente l'una dall'altra, danno al software una struttura modulare.
%Esse sono state concepite per essere facilmente estendibili o modificabili dall'utente, seguendo la logica tipica dei linguaggi orientati agli oggetti;
Esse sono state concepite per essere facilmente estendibili o modificabili, seguendo la logica tipica dei linguaggi orientati agli oggetti; infatti, grazie alla proprietà del \emph{polimorfismo}, l'utente può fornire un'implementazione alternativa delle funzioni presenti in una categoria (\textcolor{red}{provo a spiegarlo meglio introducendo le classi di base e le classi derivate?}).
%Di tutte le classi messe a disposizione, \geant{} richiede obbligatoriamente l'implementazione e l'istanziazione di tre, ovvero 
%\geant mette a disposizione un grande numero di classi, le quali sono state  concepite per essere facilmente estendibili o modificabili dall'utente, seguendo la logica tipica dei linguaggi orientati agli oggetti.
%L'implementazione e l'istanziazione di queste classi sono obbligatorie in tre casi, ovvero
%\geant{} mette a disposizione un grande numero di classi, ma per tre di loro l'implementazione e l'istanziazione sono obbligatorie.
\geant{} mette a disposizione un grande numero di classi, richiedendo obbligatoriamente l'implementazione e l'istanziazione per tre di loro: 
\begin{itemize}
	\item la classe dedicata alla definizione della geometria e dei materiali;
	\item la classe prevista per la definizione delle particelle, dei processi fisici e dei parametri di cut-off;
	\item la classe rivolta alla generazione delle particelle primarie.
\end{itemize}


%Altre classi

Le altre classi sono, invece, opzionali e, a seconda delle esigenze, l'utente può modificarne il comportamento di default definendo la propria implementazione; 
%ad esempio, ai fini di questo lavoro è stato necessario personalizzare la classe che rappresenta ogni ``passo'' della traccia della particella, facendo in modo che ad ogni step venisse estratta l'informazione sulla perdita di energia e sulla posizione.
%
ad esempio, in \geant{} esiste una classe che rappresenta ogni ``passo'' (più propriamente chiamato \emph{step}) della traccia di una particella, sia essa primaria o secondaria.
%, laddove per passo possiamo immaginare un segmento che compone la traiettoria.
L'utente può personalizzare tale classe, facendo in modo che ad ogni step vengano estratte alcune informazioni, come la posizione e l'energia della particella.
%In \geant{} la traccia della particella è divisa in \emph{step}, che, per comodità, possiamo immaginare come dei segmenti.
%Grazie ad un'apposita classe, è possibile accedere a diverse informazioni legate a tale step, come estremi 


\section{\iflanguage{italian}{Gli aspetti principali della simulazione}{Simulation main aspects}}

%La simulazione implementata per questo lavoro di tesi considera una matrice di telescopi SiC-CsI.
%Allo scopo di valutare le prestazioni di PID
Nell'ambito del presente lavoro di tesi è stata realizzata un'applicazione in \geant{} per simulare la risposta di un sistema di telescopi SiC-CsI agli ioni di interesse per il progetto NUMEN.
Nel seguito di questa sezione vengono illustrate nel dettaglio le caratteristiche di tale simulazione.




\subsection{\iflanguage{italian}{La geometria e i materiali}{Geometry and materials}} \label{par:geometria}

Considerando un sistema di riferimento in cui l'asse $z$ è individuato dalla direzione di propagazione delle particelle, i telescopi sono fra loro separati di 2~mm lungo la direzione $x$ e di 1~mm lungo la direzione $y$.

%Ciascun telescopio è formato da tre parti: il volume attivo del rivelatore al SiC, il substrato morto dello stesso rivelatore e il cristallo allo CsI.
Ciascun telescopio è formato da due componenti, il rivelatore al carburo di silicio (SiC) e il cristallo allo ioduro di cesio (CsI), le quali sono poste a contatto.
Per tenere in considerazione il substrato morto del rivelatore al SiC, tale componente è, a sua volta, costituita da due parti: il volume attivo e il substrato morto.
%In accordo con le 
%
%Un importante aspetto della simulazione riguarda lo spessore dei rivelatori.


%Dal momento che nuovi sviluppi tecnologici hanno reso possibile la rimozione quasi totale del substrato, sono state svolte anche delle simulazioni in cui il suo spessore era ridotto a 10~$\mu$m. 
%Per quanto riguarda il cristallo di CsI, lo spessore è stato posto uguale a 1~cm.


%Poiché uno degli obiettivi di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità,  sono stati considerati diversi valori per le dimensioni trasversali; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.
%Poiché uno degli obiettivi di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità,  per le dimensioni trasversali dei telescopi sono stati presi in esame diversi valori; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.
Poiché uno degli obiettivi principali di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità, sono state condotte diverse simulazioni al variare delle dimensioni trasversali dei telescopi; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.




%Lo spessore del primo è di 100~$\mu$m, mentre quello del secondo è di 350~$\mu$m.
%Un altro aspetto importante della simulazione riguarda lo spessore del rivelatore al SiC; infatti, sebbene la collaborazione abbia suggerito 
%Per quanto riguarda lo spessore dei due stadi del telescopio, la collaborazione aveva individuato come probabile soluzione l'utilizzo di rivelatori al SiC da 100~$\mu$m e di cristalli allo CsI di 1~cm. 

%Lo standard tecnologico attuale prevede che un rivelatore al SiC di tale spessore abbia un substrato morto spesso 350~$\mu$m.
Per quanto riguarda lo spessore dei due stadi del telescopio, in accordo con la soluzione individuata dalla collaborazione, sono stati simulati rivelatori al~SiC da 100~$\mu$m e cristalli allo CsI da 1~cm, mentre per il substrato morto si è considerato un valore di 350~$\mu$m.
%Gli spessori tenuti in considerazione erano di 100~$\mu$m per il rivelatore al SiC, di 350~$\mu$m per il substrato morto e di 1~cm per il cristallo allo CsI.
Tuttavia, dal momento che nuovi sviluppi tecnologici hanno reso possibile la rimozione quasi totale degli strati morti, si è esaminato anche il caso in cui lo spessore del substrato fosse ridotto a 10~$\mu$m. 
È stato, dunque, effettuato un confronto tra le due diverse condizioni, allo scopo di valutare le conseguenze sulle capacità di~PID.





%Sebbene il muro di telescopi comprenderà oltre 1000 
%La simulazione ha considerato un unico modulo di $2 \times 5$ rivelatore.
Dal momento che per gli scopi di questo lavoro non era necessario includere l'intero muro di oltre 1000 telescopi, tutte le simulazioni svolte hanno preso in esame una matrice $3 \times 3$ di elementi.
In Figura~\ref{fig:simulazione_muro} è mostrato l'aspetto assunto da tale matrice nella simulazione \geant. (\textcolor{red}{sarebbe meglio dire che ho preso in considerazione un modulo $2 \times 5$?})
%In Figura~ è possibile vedere la realizzazione grafica di \geant{} di un modulo $2 \times 5$ del sistema di rivelazione.

\begin{figure} [!p]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici/wall11_ritagliato_schiarito.png}
	\caption{Una matrice di $3 \times 3$ telescopi: in rosso il rivelatore al SiC, in verde il substrato morto di tale rivelatore e in blu il cristallo allo CsI.} \label{fig:simulazione_muro}
\end{figure}


\subsection{\iflanguage{italian}{La generazione delle particelle primarie}{Primary particles generation}} \label{par:particelle_primarie}

%Le particelle primarie simulate comprendono tre degli ioni di maggiore interesse per NUMEN, ovvero \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne}. 
%In alcune simulazioni sono stati coinvolti anche altri isotopi di tali specie nucleari, 
Le particelle primarie simulate comprendono tre degli ioni di maggiore interesse per NUMEN, ovvero \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne}, coinvolgendo in alcune simulazioni anche altri isotopi di tali specie atomiche (\textcolor{red}{dico esplicitamente quali?}).


In ciascun evento, la particella primaria è generata in modo casuale sulla faccia frontale di un rivelatore al SiC, con una direzione estratta casualmente all'interno di un angolo corrispondente ad un cono con un'apertura di 20\textdegree{}. 


%Allo scopo di coprire un ampio range energetico, realisticamente significativo per NUMEN, le particelle primarie hanno un'energia scelta casualmente fra 500 e 1000~MeV.
Allo scopo di valutare la capacità di PID in un ampio range energetico, realisticamente significativo per NUMEN, sono state simulate particelle primarie con un'energia scelta casualmente fra 500 e 1000~MeV.
%Dal momento che l'apparato sperimentale si incardina sulle proprietà dello spettrometro magnetico MAGNEX, 

È bene ricordare che negli spettrometri magnetici la posizione di una particella al piano focale è correlata alla sua energia; infatti, a partire dalla nota relazione
\begin{equation} \label{eq:legge_spettrometri}
B  \rho \, = \,  \frac{p}{q} \, 
\end{equation}
laddove $B$ è il campo magnetico, mentre $\rho$, $p$ e $q$ sono, rispettivamente, il raggio di curvatura, l'impulso e la carica della particella, sotto opportune condizioni è possibile affermare che
\begin{equation} \label{eq:legge_spettrometri_approx}
B x_{foc} \, \approx \, B  \rho  \, \propto \,  \frac{\sqrt{m}}{q} \sqrt{E}
\end{equation}
Dunque, per tenere in considerazione questo aspetto, alcune simulazioni sono state svolte tenendo fissata la rigidità magnetica $B \rho$ degli ioni primari e variandone in corrispondenza l'energia.
%Inoltre, dal momento che negli spettrometri magnetici la posizione di una particella al piano focale è correlata alla sua energia, in accordo con la nota relazione
%\begin{equation} \label{eq:legge_spettrometri}
%B  \rho \, = \,  \frac{p}{q}
%\end{equation}
%laddove $B$ è il campo magnetico, mentre $\rho$, $p$ e $q$ sono, rispettivamente, il raggio di curvatura, l'impulso e la carica della particella, alcune simulazioni sono state svolte tenendo fissato la rigidità magnetica $B \rho$ degli ioni primari.
(\textcolor{red}{secondo lei è meglio inserire la relazione del $B \rho $ nel cap 1?})


\subsection{\iflanguage{italian}{I processi fisici}{Physics processes}}


Affinché la simulazione possa riprodurre con la maggiore accuratezza possibile i risultati sperimentali reali, è di cruciale importanza la scelta dei processi fisici da considerare allo scopo di definire il comportamento delle particelle.
Per gli scopi di questo lavoro, in una prima fase sono state prese in esame soltanto le interazioni elettromagnetiche, oltre ai processi di decadimento e di decadimento radioattivo, in quanto sufficienti a separare i luoghi di specie atomiche diverse nelle matrici $\Delta E - E$.
Successivamente, sono state aggiunte anche le interazioni adroniche, incorporando, dunque, processi di scattering elastico e inelastico e meccanismi di reazioni nucleari.

In Figura~\ref{fig:simulazione_evento} è riportata la visualizzazione grafica della simulazione di 20~eventi nel caso in cui il modello dei processi fisici comprenda sia le interazioni elettromagnetiche sia quelle adroniche; infatti, in nero sono raffigurate le tracce degli ioni primari, mentre in altri colori sono mostrate le tracce delle particelle secondarie originate da reazioni nucleari. 



\begin{figure} [!p]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici/evento5_ritagliato.png}
	\caption{Rappresentazione grafica della simulazione di 20~eventi: in nero le tracce degli ioni primari (\ce{^{18}O}), in altri colori le tracce delle particelle secondarie prodotte da reazioni nucleari con i nuclei del mezzo: dal momento che riescono ad uscire fuori dal rivelatore, si tratta, probabilmente, di particelle leggere, come protoni, neutroni e particelle $\alpha$.} \label{fig:simulazione_evento}
\end{figure}




%Non sono state modificate le impostazioni di default di
Una delle componenti fondamentali di \geant{} riguarda la scelta dei parametri di cut-off; infatti, è possibile stabilire una soglia, in range o in energia, al di sotto delle quale non viene generata la particella secondaria.
Dal momento che ai fini di questo lavoro una modifica dei parametri di cut-off non avrebbe portato a significativi cambiamenti dei risultati, si è scelto di mantenerne le impostazioni di default.



\subsection{\iflanguage{italian}{Tracciamento delle particelle}{Particles step}}

%In \geant{} la traccia della particella è divisa in \emph{step}, che, per comodità, possiamo immaginare come dei segmenti.
%Grazie ad un'apposita classe, è possibile accedere a diverse informazioni legate a tale step.
Come anticipato nella sezione precedente, in \geant{} è possibile dare la propria implementazione della classe che rappresenta gli step di una particella.
Dal momento che, ai fini di questo lavoro, si volevano valutare le conseguenze sulla PID causate dagli effetti di bordo dei rivelatori, era necessario sapere punto per punto la posizione dello ione. 
Dunque, è stato modificato il comportamento di default di questa classe, affinché ad ogni step si conoscessero la posizione e il deposito di energia.
(\textcolor{red}{Spiego più in dettaglio che in realtà venivano estratti gli estremi dello step e poi veniva estratto un punto casuale fra tali estremi?})








\subsection{\iflanguage{italian}{Elaborazione post-simulazione}{Post-simulation processing}}

I dati prodotti dalla simulazione, scritti in un tree, sono stati elaborati da una macro di ROOT~\cite{brun:nima97} in cui vengono aggiunte alcune caratteristiche tipiche dei rivelatori reali e vengono ricostruiti gli spettri energetici.
%In primo luogo, ciascun deposito di energia viene pesato con una funzione di r
%In primo luogo, dal momento che 
%
%In primo luogo, a causa del processo di produzione, i rivelatori al SiC presentano nel volume sensibile un bordo esterno completamente inattivo, dove la carica generata per ionizzazione non viene raccolta, ed una regione di transizione, in cui la carica prodotta viene raccolta soltanto in parte.
In primo luogo, a causa del processo di produzione, i rivelatori al SiC presentano nel volume sensibile un bordo esterno completamente inattivo ed una regione di transizione: nel primo la carica generata per ionizzazione non viene raccolta, nella seconda viene raccolta soltanto in parte.
Secondo le misurazioni effettuate, la zona totalmente morta ha una lunghezza di circa 200~$\mu$m, mentre la regione di transizione ha un'estensione di 50~$\mu$m. 
%Nella macro si è tenuto conto di tali \emph{effetti di bordo} pesando ciascun deposito di energia con una \emph{funzione di risposta} lineare, che nel caso unidimensionale sarebbe così definita: 
%\begin{equation}
%f(x) =
%\begin{cases}
%1        & \quad  x<a \\
%\alpha x & \quad  b<x<a\\
%0        & \quad  x>b
%\end{cases}
%\end{equation}
%
Nella macro si è tenuto conto di tali \emph{effetti di bordo} pesando ciascun deposito di energia con una \emph{funzione di risposta} così definita: nella zona interamente attiva era pari ad uno, nella regione di transizione decresceva linearmente e nella zona del tutto inattiva aveva valore nullo (\textcolor{red}{Secondo lei è più chiaro se esplicito la formula del caso unidimensionale?}).

%Nella macro, inoltre, sommando le diverse perdite di energia, per ogni evento veniva ricostruito il deposito energetico totale nel rivelatore al SiC e nel cristallo allo CsI.
Nella macro, inoltre, sommando le diverse perdite di energia, per ogni evento viene ricostruito il deposito energetico totale, sia per il rivelatore al SiC sia per il cristallo allo CsI.
Mettendo insieme i depositi di energia di tutti gli eventi, si riproducono gli spettri energetici degli ioni nei due stadi del telescopio.
A questo livello, soltanto le fluttuazioni statistiche legate alla ionizzazione sono tenute in considerazione.
Dunque, al fine di riprodurre le risoluzioni energetiche tipiche dei rivelatori in esame, lo spettro energetico è stato ``allargato'' campionando ciascun deposito di energia con una distribuzione gaussiana, la cui espressione è
%\begin{equation}
%	f(E) = A \, \mbox{e}^{- \frac{E - E_0}{2 {\sigma}^2}}
%\end{equation}
\begin{equation}
	f(E, E_0, \sigma) = A \, \exp \left( \frac{E - E_0}{2 {\sigma}^2} \right)
\end{equation}
dove $A$ è una costante di normalizzazione, $E_0$ è il valore originario del deposito di energia, $E$ è il valore dopo il campionamento e $\sigma$ è la deviazione standard.
Di tale distribuzione, noto il valore medio $E_0$, bisognava scegliere la $\sigma$ in modo tale che la risoluzione energetica ricavata dalla simulazione fosse confrontabile con quella sperimentale.
%Dal momento che la risoluzione energetica è generalmente espressa come la somma in quadratura di un termine legato alle fluttuazioni statistiche del numero dei portatori e di uno dovuto al rumore elettronico, nella macro si è parametrizzata la $\sigma$ nel modo seguente
La risoluzione energetica è generalmente espressa come la somma in quadratura di un termine legato alle fluttuazioni statistiche del numero dei portatori, proporzionale a $E^{-1/2}$, e di uno dovuto al rumore elettronico, proporzionale a $E^{-1}$~\cite{knoll:10}.
Dunque, dal momento che la $\sigma$ può essere messa in relazione alla risoluzione energetica $R$ attraverso la~formula
\begin{equation}
	R \,  = \, \frac{\mbox{FWHM}}{E} \, = \, \frac{2.35 \, \sigma}{E}
\end{equation}
nella macro si è parametrizzata la deviazione standard nel modo seguente
\begin{equation}
\sigma = \sqrt{a + b \, E}
\end{equation}
laddove $a$ e $b$ sono due costanti.
%che assumono valori diversi a seconda che si consideri il rivelatore al SiC o il cristallo allo CsI. 
Nella somma al secondo membro, il primo addendo corrisponde al termine legato al rumore elettronico, mentre il secondo rappresenta quello causato dalle fluttuazioni del numero di portatori.
%
%
%Ricordando che la FWHM è legata alla $\sigma$ dalla relazione
%\begin{equation}
%\mbox{FWHM} = 2.35 \, \sigma
%\end{equation}
%la deviazione standard risulta collegata alla risoluzione energetica.
%Dal momento che quest'ultima è generalmente determinata dalla somma in quadratura di un termine legato all
Scegliendo opportuni valori per $a$ e $b$, si è assunta per il rivelatore al SiC una risoluzione energetica intrinseca dello 0.8\% FWHM a 19.4~MeV, mentre per il rivelatore allo CsI dell'1.8\% FWHM a 850~MeV, in affinità con i valori tipici di questi dispositivi. (\textcolor{red}{Devo specificare i valori di a e b scelti nei due casi?})







%\clearpage


\section{\iflanguage{italian}{I risultati}{Results}}

In questa sezione vengono presentati i risultati ottenuti dalle simulazioni \geant{} del sistema di telescopi SiC-CsI.
Poiché l'obiettivo principale di questo lavoro di tesi consiste nella valutazione delle prestazioni di PID di tale sistema, la maggior parte delle simulazioni ha lo scopo di stimare la percentuale di errore che si commetterebbe nell'identificazione degli ioni di interesse per NUMEN utilizzando la tecnica $\Delta E - E$.

È bene ricordare che tale tecnica prevede la correlazione fra la perdita di energia $\Delta E$ e l'energia cinetica totale $E$. In riferimento al caso in esame, $\Delta E$ corrisponde all'energia persa dalla particella primaria nel rivelatore al~SiC (che da ora in poi indicheremo con $ \Delta E_{SiC}$), mentre $E$ equivale alla sua energia cinetica iniziale. Nelle simulazioni svolte, quest'ultima quantità è data da
\begin{equation}
	E \, = \, \Delta E_{SiC} + E_{sub} + E_{CsI}
\end{equation}
laddove $E_{sub}$ è l'energia persa nel substrato morto ed $E_{CsI}$ è l'energia residua rilasciata nel cristallo allo CsI.
In realtà, $E_{sub}$ non sarebbe sperimentalmente accessibile; di conseguenza, per tenere conto delle energie realmente misurabili, bisogna introdurre la quantità $E_{tot}$, definita nel modo seguente
\begin{equation}
	E_{tot} \, = \, \Delta E_{SiC} + E_{CsI}
\end{equation}

%Dal momento che uno degli aspetti studiati in questo lavoro consiste nel valutare la differenza fra la correlazione $\Delta E - E_{tot}$ e quella $\Delta E - E_{resid}$, per maggiore chiarezza nel prosieguo verrà specificato se  
Inoltre, dal momento che uno degli aspetti studiati in questo lavoro consiste nel valutare se la correlazione $\Delta E_{SiC} - E_{CsI}$ può garantire prestazioni analoghe a quella $\Delta E_{SiC} - E_{tot}$, nel prosieguo verrà specificato quale tipo di correlazione si sta considerando.
%Dunque, dal momento che nel prosieguo verrà valutata la differenza fra le matrici 

%Per semplicità della trattazione si è preferito suddividere la sezione in paragrafi specifici, evidenziando di volta in volta quali parametri sono stati variati e quali sono stati tenuti fissi.
%Tenendo in mente questo obiettivo, per semplicità della trattazione si è preferito esporre i risultati evidenziando di volta in volta quali parametri sono stati variati e quali sono stati tenuti fissi.
Per semplicità della trattazione si è preferito esporre i risultati in modo schematico, evidenziando di volta in volta quali parametri sono stati variati e quali sono stati tenuti fissi.

%\subsection{\iflanguage{italian}{Caso ideale}{Ideal case}}
\subsection{\iflanguage{italian}{Particelle monocromatiche, ortogonali e centrali }{Monochromatic, orthogonal and central particles}}


Come primo esempio si è scelto di illustrare i risultati di un caso ideale in cui le particelle primarie sono generate con un'energia di 1000~MeV ed incidono ortogonalmente e centralmente al telescopio, il quale ha, in questo caso, dimensioni trasversali di 1~cm $\times$ 1~cm.
Nella prima fase di implementazione della simulazione, il modello dei processi fisici utilizzato prendeva in considerazione soltanto le interazioni elettromagnetiche, i processi di decadimento e di decadimento radioattivo.
Dal momento che la formula di Bethe-Block è ricavata tenendo conto della sola interazione elettromagnetica, il modello adottato è sufficiente a separare ioni diversi nelle matrici $\Delta E_{SiC} - E_{tot}$.
Questa affermazione viene confermata dalla Figura~\ref{fig:deltaE_ETot}, in cui è possibile notare che i luoghi di \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne} sono chiaramente distinti.
Innanzitutto, si sottolinea che le matrici si dispongono ad $E_{tot}$ diversi perché la parte di energia persa nel substrato morto dipende dal numero atomico ($Z$) dello ione.
In secondo luogo, si fa notare che al di sotto di ciascuna delle tre matrici sono presenti degli eventi in cui l'energia residua è stata misurata correttamente, mentre la perdita di energia risulta inferiore al valore ``corretto'' (\textcolor{red}{Non so se va bene definirlo ``corretto''}): si tratta di eventi in cui la carica prodotta nel rivelatore al SiC è stata raccolta parzialmente. 
Tali eventi costituiscono la principale componente di errore nella PID, in quanto, potendo andare a posizionarsi sul luogo di uno ione diverso, in una procedura di identificazione effettuata mediante tagli grafici verrebbe attribuito loro uno~$Z$ sbagliato.
Si deduce, quindi, che per avere delle buone capacità di PID è essenziale che la frazione di questi eventi rispetto al totale sia piccola.


\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Particelle_monocromatiche/deltaE_ETot_punti_grandi.png}
	\caption{Matrici $\Delta E_{SiC} - E_{tot}$ per \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne}.} \label{fig:deltaE_ETot}
\end{figure}




In Figura~\ref{fig:ETot} e in Figura~\ref{fig:deltaE_Tot} sono riportate, rispettivamente, le proiezioni sull'asse $E_{tot}$ e sull'asse $\Delta E_{SiC}$ delle matrici $\Delta E_{SiC} - E_{tot}$: esse rappresentano, dunque, gli spettri energetici misurati dal rivelatore al SiC e dal rivelatore allo CsI.
Effettuando un fit gaussiano sul picco dell'\ce{^{18}O} nello spettro $\Delta E_{SiC}$, si trova una FWHM di 1.1~MeV, corrispondente ad una risoluzione di 5.8\%.
Poiché questo valore è ben più grande della risoluzione intrinseca assunta per tale rivelatore, si deduce che in questo caso la componente più significativa della risoluzione compete alle fluttuazioni nel processo di ionizzazione.


\begin{figure} [!p]
	\centering
	\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_monocromatiche/ETot.png}
	\caption{Spettro in $E_{tot} = \Delta E_{SiC} + E_{CsI}$.} \label{fig:ETot}
\end{figure}


\begin{figure} [!p]
	\centering
	\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_monocromatiche/deltaE_Tot.png}
	\caption{Spettro in $ \Delta E_{SiC} $.} \label{fig:deltaE_Tot}
\end{figure}









%\subsection{\iflanguage{italian}{Processi fisici senza interazioni adroniche}{Physics process without adronic interactions}}
\subsection{\iflanguage{italian}{Particelle non monocromatiche, non ortogonali e non centrali }{Not monochromatic, not orthogonal and not central particles}} \label{par:particelle_non_monocromatiche}



\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Particelle_non_monocromatiche/deltaE_ETot_full_energy.png}
	\caption{Matrici $\Delta E_{SiC} - E_{tot}$.} \label{fig:deltaE_ETot_full_energy}
\end{figure}



In questo secondo esempio le particelle primarie hanno un'energia scelta in modo casuale fra 500 e 1000~MeV, la loro posizione iniziale è estratta casualmente sulla faccia frontale del rivelatore al SiC e la direzione del loro impulso varia in modo casuale in un cono di apertura di 20\textdegree{}.
Inoltre, anche in questo caso viene utilizzato il modello dei processi fisici dell'esempio precedente; la geometria e le dimensioni dei telescopi restano, invece, uguali a quelle dell'esempio precedente.
Le corrispondenti matrici $\Delta E_{SiC} - E_{tot}$ sono rappresentate in Figura~\ref{fig:deltaE_ETot_full_energy}: in primo luogo, si vede la formazione delle bande previste dalla formula di Bethe-Block, che appaiono ben separate lungo tutto il range energetico esplorato.
%Inoltre, a differenza del caso precedente si nota la comparsa di eventi in cui la perdita di energia $\Delta E_{SiC}$ viene misurata correttamente, mentre l'energia $E_{tot}$ ha un valore inferiore rispetto a quello ``corretto''.
Inoltre, rispetto al caso precedente, fanno la loro comparsa degli eventi in cui la perdita di energia $\Delta E_{SiC}$ viene misurata correttamente, mentre l'energia $E_{tot}$ ha un valore inferiore rispetto a quello ``corretto''. 
Ciò dipende da quegli eventi in cui le particelle escono fuori dal rivelatore al CsI, non rilasciando totalmente la loro energia residua.
A causa del motivo precedentemente citato, anche questi eventi introducono una componente di errore nella PID.
Per meglio comprendere l'entità della frazione di eventi spuri (\textcolor{red}{si possono definire così?}), si è riportata in Figura~\ref{fig:fetta} la proiezione sull'asse verticale della ``fetta'' di energia compresa fra 600 e 700~MeV: come si può notare, tali eventi costituiscono un continuo che si estende fino a zero e rendono asimmetriche le distribuzioni. 
%Allo scopo di dare una stima quantitativa della frazione di nuclei potenzialmente male identificati, il taglio per separare le differenti specie atomiche è stato scelto come il punto mediano fra due bande


\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Particelle_non_monocromatiche/fetta_quadrata.png}
	\caption{Proiezione sull'asse $\Delta E_{SiC}$ della fetta in $E_{tot}$ compresa tra 600 e 700~MeV.} \label{fig:fetta}
\end{figure}



\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Contaminazione/contaminazione.png}
	\caption{Proiezione sull'asse $\Delta E_{SiC}$ della fetta in $E_{tot}$ compresa tra 600 e 700~MeV.} \label{fig:fetta_con_contaminazione}
\end{figure}










Allo scopo di dare una stima quantitativa della frazione di nuclei potenzialmente male identificati, si è proceduto nel modo seguente: per ogni fetta di energia in $E_{tot}$, si è effettuata una proiezione sull'asse $\Delta E_{SiC}$; dopo di che, per ogni coppia di specie atomiche, si è calcolato il punto mediano fra i valori medi delle due distribuzioni; infine, si è determinata la frazione di eventi al di sotto (o al di sopra) del punto mediano.
Il risultato di tale procedura è illustrato in Figura~\ref{fig:leakage}, dove il range energetico è stato suddiviso in intervalli da 100~MeV e si è scelto di rappresentare i dati soltanto laddove erano presenti tutte e tre le bande.
Si può notare che la \textcolor{red}{contaminazione} (\textcolor{red}{posso usare questo termine?}) da una specie atomica con $Z$ più grande verso una con $Z$ più piccolo è nettamente maggiore; infatti, le percentuali che si trovano in Figura~\ref{fig:leakage}.a sono comprese fra il 7\% e il 15\%, mentre quelle in Figura~\ref{fig:leakage}.b sono inferiori all'1\%.
In entrambi i casi si può osservare che la frazione di nuclei erroneamente identificati ha un andamento decrescente al crescere dell'energia.
Di conseguenza, a basse energie, dove gli effetti di raccolta parziale della carica sono maggiormente significativi, la capacità di separare gli ioni peggiora.

I due grafici in Figura~\ref{fig:leakage} sono estremamente importanti nella valutazione dell'idoneità di questo sistema di rivelazione agli scopi di NUMEN, in quanto per riuscire a misurare processi rari come quelli di DCE è essenziale che il segnale venga riconosciuto e che il fondo non venga identificato come segnale: se, ad esempio, consideriamo che il segnale da ricercare sia \ce{^{18}Ne}, allora gli eventi di tale ione identificati come \ce{^{18}O} o \ce{^{18}F} costituiscono una perdita di segnali corretti. 
Dunque, è necessario stabilire un limite inferiore alla probabilità di riconoscimento del segnale, che, ai fini di questo lavoro di tesi, può essere posto all'80\%.
D'altra parte, sempre considerando che il segnale sia costituito da \ce{^{18}Ne}, gli eventi di \ce{^{18}O} e \ce{^{18}F} identificati come \ce{^{18}Ne} rappresentano, invece, una contaminazione, ovvero fondo scambiato per segnale.
In questo caso bisogna fissare un limite superiore a tale contaminazione, che, per gli scopi di questo lavoro, è stato posto allo 0.5\%.

%(\textcolor{red}{Scrivere la parte sull'efficienza di riconoscimento del segnale})




\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_non_monocromatiche/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_non_monocromatiche/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{tot}$: in (a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage}
\end{figure}


%Uno studio interessante riguarda il confronto fra la correlazione $\Delta E_{SiC} - E_{tot}$ e quella $\Delta E_{SiC} - E_{CsI}$: in Figura~\ref{fig:deltaE_ERes}.
A questo punto, è interessante studiare la correlazione $\Delta E_{SiC} - E_{CsI}$: in Figura~\ref{fig:deltaE_ERes} sono riportate le matrici delle tre specie di interesse, le quali continuano ad essere ben separate per tutto il range energetico. 
%Dal confronto con la Figura~\ref{fig:deltaE_ETot_full_energy} si nota che tali matrici si estendono ad energie inferiori, in quanto alla variabile sull'asse orizzontale viene a mancare il contributo di $\Delta E_{SiC}$. 
Confrontando tali matrici con quelle in Figura~\ref{fig:deltaE_ETot_full_energy}, non si notano sostanziali differenze, in particolare per quanto riguarda la densità degli eventi spuri.
Questa affermazione è supportata dalla Figura~\ref{fig:leakage_res}, nella quale si riscontrano percentuali simili a quelle viste in Figura~\ref{fig:leakage}.
L'unica differenza sembra essere dovuta al punto in Figura~\ref{fig:leakage_res}.a ad 850~MeV, per il quale si osservano percentuali lievemente maggiori del suo corrispettivo in Figura~\ref{fig:leakage}.a. 
%Ciò sembra essere legato al modo in cui si dispongono gli eventi con raccolta di carica incompleta; 
Ciò è legato alla correlazione delle due grandezze;
infatti, mentre nelle matrici $\Delta E_{SiC} - E_{tot}$ tali eventi scendono verso l'asse orizzontale con una certa inclinazione, nelle matrici $\Delta E_{SiC} - E_{CsI}$ la loro discesa verso all'asse $E_{CsI}$ procede in direzione perpendicolare. 
Sulla base di questo risultato è possibile sostenere che non è necessario effettuare una calibrazione energetica del telescopio, in quanto ai fini della PID non vi è l'esigenza di sommare i valori di energia misurati dai due rivelatori.
Dal momento che il muro di telescopi sarà composto da oltre 1000 dispositivi, la possibilità di evitarne la calibrazione consentirebbe un notevole risparmio di tempo.
%Poiché la correlazione $\Delta E_{SiC} - E_{CsI}$ offre risultati paragonabili a quelli della correlazione $\Delta E_{SiC} - E_{tot}$, da questo momento in poi verranno presentate le matrici soltanto 


\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Particelle_non_monocromatiche_Resid/deltaE_ERes.png}
	\caption{Matrici $\Delta E_{SiC} - E_{CsI}$.} \label{fig:deltaE_ERes}
\end{figure}






\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_non_monocromatiche_Resid/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Particelle_non_monocromatiche_Resid/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$: in (a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res}
\end{figure}

Poiché anche in altri casi si è riscontrato che la correlazione $\Delta E_{SiC} - E_{CsI}$ offre risultati paragonabili a quelli di $\Delta E_{SiC} - E_{tot}$, da questo momento in poi verranno presentate soltanto le matrici $\Delta E_{SiC} - E_{CsI}$.









%\clearpage

\subsection{\iflanguage{italian}{Modello di interazioni adroniche}{Model with adronic interactions}} \label{par:interazioni_adroniche}






Rispetto all'esempio precedente, in questa simulazione la geometria e le caratteristiche delle particelle primarie restano invariate, mentre il modello dei processi fisici adesso include le interazioni adroniche. 
Le corrispondenti matrici $\Delta E_{SiC} - E_{CsI}$ sono riportate in Figura~\ref{fig:deltaE_ERes_adron}: come si può notare, a differenza del caso in cui erano considerate soltanto le interazioni elettromagnetiche, adesso si osserva per tutte e tre le specie nucleari la comparsa di eventi ad un'energia $\Delta E_{SiC}$ più alta di quella delle rispettive bande.
Ciò è dovuto a meccanismi di reazioni nucleari e a processi di scattering inelastico, nei quali può essere rilasciata una notevole quantità di energia (\textcolor{red}{non sono molto sicuro di questa cosa}).
La presenza di questi eventi non sembra provocare significativi cambiamenti nelle capacità di PID, in quanto, come si può evincere dalla Figura~\ref{fig:leakage_res_adron}, le percentuali di nuclei potenzialmente male identificati aumenta di meno dell'1\%. 
Dunque, è evidente che la maggior parte degli eventi spuri è originata da raccolta di carica incompleta, come d'altronde era lecito aspettarsi vista la bassa probabilità che avvenga un'interazione adronica (\textcolor{red}{giusto?}).


\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Interazioni_adroniche/deltaE_ERes.png}
	\caption{Le matrici $\Delta E_{SiC} - E_{CsI}$ considerando un modello di processi fisici che comprenda anche le interazioni adroniche.} \label{fig:deltaE_ERes_adron}
\end{figure}




\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Interazioni_adroniche/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Interazioni_adroniche/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, utilizzando un modello che comprenda anche le interazioni adroniche: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_adron}
\end{figure}


\clearpage
\subsection{\iflanguage{italian}{Studio della granularità}{Study of granularity}}

Uno degli obiettivi fondamentali di questo lavoro di tesi consiste nell'ottimizzazione delle dimensioni trasversali dei telescopi, al fine di minimizzare la percentuale di eventi in cui la carica è stata raccolta parzialmente. 
Dal momento che la lunghezza della cornice completamente inattiva e della regione di transizione dovrebbero essere circa costanti pur variando la superficie del rivelatore al~SiC, ci si aspetta che all'aumentare delle dimensioni trasversali del telescopio la frazione degli eventi con raccolta di carica incompleta diminuisca.
Tenendo presenti gli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono stati esaminati tre casi: $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}. 
In ciascuna delle tre possibilità le particelle primarie sono state generate mantenendo i parametri elencati nel Paragrafo~\ref{par:interazioni_adroniche}.
Per quanto riguarda il primo caso, i plot di riferimento sono quelli mostrati nel paragrafo precedente, mentre per gli altri due vengono adesso esposti.

\subsection*{Dimensioni trasversali: 1.5~cm $\times$ 1.5~cm}
%\paragraph*{Dimensioni trasversali: 1.5~cm $\times$ 1.5~cm.}
%Come si può notare dalla Figura~\ref{fig:deltaE_ERes_1.5}, le matrici $\Delta E_{SiC} - E_{CsI}$ nel caso in esame 




Poiché nel caso in esame le matrici $\Delta E_{SiC} - E_{CsI}$ continuano ad essere ben separate e non mostrano variazioni percettibili rispetto a quelle in Figura~\ref{fig:deltaE_ERes_adron}, si è scelto di non riportarle.
Dalla Figura~\ref{fig:leakage_res_1.5} si può, invece, notare come la percentuale di eventi con raccolta di carica incompleta sia diminuita per tutte le coppie di specie atomiche; in particolare, confrontando la Figura~\ref{fig:leakage_res_1.5}.a con la Figura~\ref{fig:leakage_res_adron}.a, si evidenzia una diminuzione di circa il 2\% per ogni intervallo energetico.

\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/1.5per1.5/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/1.5per1.5/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, considerando una superficie totale di $1.5 \times 1.5$~cm\ap{2}: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_1.5}
\end{figure}






\subsection*{Dimensioni trasversali: 2~cm $\times$ 2~cm}
%\paragraph*{Dimensioni trasversali: 2~cm $\times$ 2~cm.}
Anche in questo caso, per i motivi esposti precedentemente, si è preferito non mostrare le matrici $\Delta E_{SiC} - E_{CsI}$.
In Figura~\ref{fig:leakage_res_2} si può osservare che, aumentando ulteriormente le dimensioni trasversali del telescopio, la percentuale di nuclei identificati erroneamente si riduce.
In questo caso, tuttavia, l'entità della diminuzione è inferiore rispetto al caso precedente, in quanto per le coppie in Figura~\ref{fig:leakage_res_2}.a corrisponde a circa l'1\%, mentre per quelle in Figura~\ref{fig:leakage_res_2}.b si osservano soltanto piccolissimi cambiamenti.


\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/2per2/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/2per2/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, considerando una superficie totale di $2 \times 2$~cm\ap{2}: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_2}
\end{figure}









\subsection*{Conclusioni}
%\paragraph*{Conclusioni.}





\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Granularita/misident_surface3.png}
	\caption{L'andamento della probabilità di identificare nuclei di \ce{^{18}Ne} come \ce{^{18}O} al variare della superficie del rivelatore e per energie pari a 450 e 850~MeV. I punti si riferiscono ai tre valori di superficie considerati nelle simulazioni.} \label{fig:misident_vs_surface}
\end{figure}




In accordo con quanto trovato, si può affermare che, al fine di minimizzare gli eventi con raccolta di carica incompleta, è opportuno avere la maggiore superficie di rivelazione possibile.
Ciò si può evincere dalla Figura~\ref{fig:misident_vs_surface}, dove è mostrato, per un caso rappresentativo, l'andamento della probabilità di errore nell'identificazione dei nuclei al variare della superficie e dell'energia.
%Ciò si spiega considerando che, a parità di lunghezza della cornice, aumentando l'area del rivelatore cresce la frazione di superficie sensibile rispetto a quella totale.
Tale andamento può essere spiegato considerando che, a parità di lunghezza della cornice, aumentando l'area del rivelatore cresce la frazione di superficie sensibile rispetto a quella totale.



Tuttavia, avere superfici più grandi significa anche aumentare il verificarsi del pile-up, in quanto cresce la probabilità che due o più ioni vadano a finire nello stesso rivelatore nella stessa finestra temporale, producendo un segnale somma di due segnali.
In Figura~\ref{fig:pile-up} è riportato il risultato di un calcolo analitico che mostra l'andamento della probabilità di avere pile-up rispetto alla probabilità di avere un solo evento al variare del flusso di particelle incidenti: come si può notare, tale quantità cresce rapidamente all'aumentare della superficie del rivelatore.
Dal momento che per gli obiettivi di NUMEN è necessario lavorare con fasci di alta intensità, è fondamentale che la probabilità di pile-up sia piccola; di conseguenza, la superficie dei telescopi non può essere eccessivamente grande.


\begin{figure} [!t]
	\centering
	\includegraphics[scale=0.55]{Grafici_Tesi/Granularita/pile-up_label2.png}
	\caption{La probabilità di avere eventi di pile-up rispetto alla probabilità di avere un singolo evento al variare del flusso di particelle incidenti e della superficie del rivelatore. La linea tratteggiata indica il flusso atteso per NUMEN.} \label{fig:pile-up}
\end{figure}


Due aspetti diversi spingono in direzioni opposte; è necessario, dunque, cercare una situazione di compromesso fra le due esigenze.
Alla luce delle considerazione svolte, la migliore condizione di granularità sembra essere rappresentata dai telescopi con dimensioni trasversali di 1.5~cm $\times$ 1.5~cm, in quanto congiunge un'alta percentuale di riconoscimento del segnale con una bassa probabilità di pile-up.





%\clearpage
\subsection{\iflanguage{italian}{Studio degli effetti di bordo}{Study of frame effects}}

Da quanto finora detto, è emerso che l'estensione della regione di transizione fra la zona inattiva e quella sensibile del rivelatore al SiC gioca un ruolo estremamente importante nella PID.
Di conseguenza, è opportuno valutare come cambia la frazione di eventi con raccolta di carica incompleta al variare della lunghezza di tale regione; 
%ciò permette, infatti, di porre dei limiti di accettabilità, che, nel caso in cui venissero superati, renderebbero i rivelatori inadatti agli scopi del progetto.
ciò permette, infatti, di porre dei limiti di accettabilità sui rivelatori, che devono essere tenuti in considerazione in fase di progettazione e rispettati durante la realizzazione.
Qualora non fosse possibile soddisfare tali requisiti, i rivelatori diventerebbero inadatti agli scopi del progetto.


Sulla base delle attuali specifiche di produzione dei rivelatori al SiC e di recenti misure, sono stati presi in esame tre valori: 20, 50 e 200~$\mu$m.
Il primo rappresenta un traguardo concreto nelle tecniche di realizzazione, il secondo è il valore medio al momento raggiungibile, il terzo costituisce lo studio di una situazione estrema.
In tutti e tre i casi, i telescopi avevano dimensioni trasversali pari a 1.5~cm $\times$ 1.5~cm, mentre lo spessore del substrato morto era di 350~$\mu$m.
La lunghezza della zona inattiva attorno alla superficie sensibile è stata fissata a 200~$\mu$m, in accordo con gli standard attuali.
%Le condizioni di generazione delle particelle primarie continuano ad essere quelle del Paragrafo~\ref{par:interazioni_adroniche}.
Le particelle primarie sono state generate mantenendo le caratteristiche esposte nel Paragrafo~\ref{par:interazioni_adroniche}.
I grafici relativi alla lunghezza di 50~$\mu$m sono già stati mostrati in Figura~\ref{fig:leakage_res_1.5}.



\subsection*{Lunghezza della regione di transizione: 20~$\mu$m}

%Le matrici $\Delta E_{SiC} - E_{CsI}$ corrispondenti al caso in esame sono riportate in Figura~: come si può notare, 
Come si evince confrontando la Figura~\ref{fig:leakage_res_1.5} con la Figura~ \ref{fig:leakage_res_20um}, diminuendo la lunghezza della regione di transizione si osserva una riduzione della percentuale di eventi con raccolta di carica incompleta dell'ordine dello 0.5\%.



\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/20um/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/20um/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, considerando una lunghezza della zona di transizione di 20~$\mu$m: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_20um}
\end{figure}


\subsection*{Lunghezza della regione di transizione: 200~$\mu$m}

Dalla Figura~\ref{fig:leakage_res_200um} si può notare che, aumentando la lunghezza della regione di transizione, la percentuale di nuclei identificati erroneamente cresce.
Tale incremento, rispetto al caso con un valore di 50~$\mu$m, è di circa il 3\%.



\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/200um/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/200um/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, considerando una lunghezza della zona di transizione di 200~$\mu$m: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_200um}
\end{figure}



\subsection*{Conclusioni}

%\subsection*{{\large Conclusioni }}

Alla luce di questi risultati, è possibile affermare che, in tutti e tre i casi considerati, il sistema di identificazione rispetta i limiti stabiliti sul riconoscimento del segnale e sulla contaminazioni.
L'andamento della percentuale di errore nell'identificazione dei nuclei in funzione della lunghezza della zona di transizione è riportato, nel caso di contaminazione di \ce{^{18}Ne} in \ce{^{18}O}, in Figura~\ref{fig:misident_vs_length}.
Oltre ai tre valori suddetti, si è valutata tale percentuale anche per una lunghezza di 500~$\mu$m, sebbene sia ben lontana dagli standard di produzione.
In questo caso la percentuale di errore è vicina al 20\%, diventando, dunque, eccessivamente alta per i requisiti del progetto.







\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Cornice/misident_length2.png}
	\caption{L'andamento della probabilità di identificare nuclei di \ce{^{18}Ne} come \ce{^{18}O} al variare della lunghezza della regione di transizione e per energie pari a 450 e 850~MeV.} \label{fig:misident_vs_length}
\end{figure}



%\clearpage
\subsection{\iflanguage{italian}{Studio dello spessore del substrato morto}{Study of dead-substrate}}




Come anticipato nel Paragrafo~\ref{par:geometria}, grazie all'utilizzo di sofisticate tecniche di lavorazione, lo spessore del substrato epitassiale del rivelatore al SiC potrebbe essere ridotto fino a 10~$\mu$m.
Tuttavia, queste tecniche non soltanto richiedono costi di produzione maggiori ma rischiano anche di danneggiare alcuni dispositivi;
dunque, è ragionevole effettuare tale operazione se i benefici portati sono superiori agli svantaggi.
Secondo questa prospettiva, nel presente lavoro di tesi sono state valutate le possibili conseguenze sulla PID, mettendo a confronto le prestazioni ottenibili al variare dello spessore del substrato morto.

%Le simulazioni sono state svolte considerando dimensioni trasversali di 1.5~cm $\times$ 1.5~cm, 
In questo studio le dimensioni trasversali dei telescopi sono state fissate a 1.5~cm $\times$ 1.5~cm, con lunghezze della regione di transizione e della cornice inattiva, rispettivamente, di 50 e 200~$\mu$m.
Le particelle primarie sono state generate mantenendo le caratteristiche del Paragrafo~\ref{par:interazioni_adroniche}.
Per il caso con substrato morto da 350~$\mu$m, le matrici $\Delta E_{SiC} - E_{CsI}$ sono riportate in Figura~\ref{fig:deltaE_ERes_1.5}, mentre i grafici sulle contaminazioni sono già stati mostrati in Figura~\ref{fig:leakage_res_1.5}.





\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/1.5per1.5/deltaE_ERes.png}
	\caption{Le matrici $\Delta E_{SiC} - E_{CsI}$ considerando uno spessore del substrato morto pari a 350~$\mu$m.} \label{fig:deltaE_ERes_1.5}
\end{figure}




\subsection*{Spessore del substrato morto: 10~$\mu$m}




\begin{figure} [!p]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Substrato/deltaE_ERes.png}
	\caption{Le matrici $\Delta E_{SiC} - E_{CsI}$ considerando uno spessore del substrato morto pari a 10~$\mu$m.} \label{fig:deltaE_ERes_substrate}
\end{figure}



%Le matrici $\Delta E_{SiC} - E_{CsI}$ relative al caso in discussione sono mostrate in Figura~\ref{fig:deltaE_ERes_substrate}: come si può notare, rispetto alla Figura~\ref{fig:leakage_res_1.5}, le bande sono collocate ad un'energia $E_{CsI}$ più alta; infatti, dal momento che il substrato morto è più sottile, le particelle perdono in esso meno energia e, di conseguenza, l'energia residua rilasciata nel rivelatore al CsI è maggiore.
Come si può evincere dal confronto tra la Figura~\ref{fig:deltaE_ERes_substrate} e la Figura~\ref{fig:deltaE_ERes_1.5}, riducendo lo spessore del substrato morto, le matrici $\Delta E_{SiC} - E_{CsI}$ si collocano ad un'energia $E_{CsI}$ più alta; infatti, dal momento che tale substrato è più sottile, le particelle perdono in esso meno energia, rilasciando nel rivelatore allo CsI un'energia residua maggiore.
Inoltre, si può notare che le bande in Figura~\ref{fig:deltaE_ERes_1.5} sono più lunghe di quelle in Figura~\ref{fig:deltaE_ERes_substrate}, in quanto, aumentando lo spessore del substrato morto, vengono introdotte maggiori fluttuazioni sull'energia, così che alcune particelle possono perdere molta più energia di altre (\textcolor{red}{giusto?}).

%Il grafico della percentuale di errore al variare di $E_{CsI}$ è, invece

Confrontando la Figura~\ref{fig:leakage_res_substrate} con la Figura~\ref{fig:leakage_res_1.5} si può osservare che vi è un aumento della percentuale di errore nell'identificazione dei nuclei, che diventa più rilevante a più bassa energia.



\begin{figure}[!p] 
	\centering
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Substrato/leakage_alto.png}}
	\hspace{10mm}
	\subfigure[]
	{\includegraphics[scale=0.5]{Grafici_Tesi/Substrato/leakage_basso.png}}
	\caption{La percentuale di nuclei identificati in modo erroneo in funzione di $E_{CsI}$, considerando una lunghezza della zona di transizione di 200~$\mu$m: in~(a) la contaminazione da specie atomiche con $Z$ maggiore verso quelle con $Z$ minore, in (b) il viceversa.} \label{fig:leakage_res_substrate}
\end{figure}



\subsection*{Conclusioni}

In accordo con quanto trovato, la riduzione dello spessore del substrato morto provoca un leggero peggioramento delle capacità di PID, sebbene vengano rispettati i limiti fissati sul riconoscimento del segnale e sulla contaminazione.
L'andamento della percentuale di errore nell'identificazione dei nuclei al variare dello spessore del substrato morto è riportato, nel caso di contaminazione di \ce{^{18}Ne} in \ce{^{18}O}, in Figura~\ref{fig:misident_vs_substrate}.
(\textcolor{red}{Ha senso mettere questo grafico con soltanto due casi studiati?})
Osservando tale grafico è possibile dedurre che, dal punto di vista dell'identificazione dei prodotti di reazione, la riduzione dello spessore del substrato morto risulta un'operazione ingiustificata.






\begin{figure} [!t]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Substrato/misident_substrate.png}
	\caption{L'andamento della probabilità di identificare nuclei di \ce{^{18}Ne} come \ce{^{18}O} al variare dello spessore del substrato morto e per energie pari a 450 e 850~MeV.} \label{fig:misident_vs_substrate}
\end{figure}




%\clearpage
\subsection{\iflanguage{italian}{Studio a fissata rigidità magnetica}{Study of fixed magnetic rigidity}}

%Dal momento che il muro di telescopi farà parte del FPD di uno spe

%Nel Paragrafo~\ref{par:particelle_primarie} è stato anticipato che 

%Nelle simulazioni finora presentate, il telescopio sul quale venivano generate le particelle primarie
%Nelle simulazioni finora discusse, le particelle primarie sono state prodotte con un'energia compresa tra 500 e 1000~MeV
Le simulazioni finora discusse hanno contemplato delle situazioni in cui sul singolo telescopio incidessero particelle primarie con un'energia compresa tra 500 e 1000~MeV.
%In realtà, dal momento che negli spettrometri magnetici la posizione di una particella al piano focale è legata alla sua energia secondo la~\ref{eq:legge_spettrometri_approx}, sul singolo telescopio possono arrivare soltanto ioni che abbiano la stessa rigidità magnetica.
In realtà, negli spettrometri magnetici la posizione di una particella al piano focale è legata alla sua energia secondo la~\ref{eq:legge_spettrometri_approx}.
%Quindi, dal momento che ad ogni telescopio corrisponde una determinata $x_{foc}$, 
Dunque, in ogni telescopio del muro possono arrivare soltanto ioni che abbiano la stessa rigidità magnetica (\textcolor{red}{È abbastanza chiaro il perché?}).
Per questo motivo è stata svolta una simulazione fissando il $B \rho$ a 1.96~Tm e calcolando per ogni nuclide la corrispondente energia: i risultati di tale calcolo sono riportati in Tabella~\ref{tab:energia}, dove si può notare che in questo caso sono stati considerati nove nuclidi.

\begin{table}[t!]
	\begin{center}
		\begin{tabular}{ccc}
			Nuclide       & &  Energia [MeV] \\
			%\hline
			\toprule
			\ce{^{16}O}  &  &  724.3 \\
			\ce{^{17}O}  &  &  683.3 \\
			\ce{^{18}O}  &  &  646.8 \\
			\ce{^{18}F}   & &  814.6 \\
			\ce{^{19}F}   & &  773.6 \\
			\ce{^{20}F}   & &  736.4 \\
			\ce{^{18}Ne}  & &  1000  \\
			\ce{^{19}Ne}  & &  950.3 \\
			\ce{^{20}Ne}  & &  905.4
		\end{tabular}
	\end{center}
	\caption{Principali picchi energetici con i relativi branching ratio dell'~\ce{^{241}Am}. Informazioni tratte da.
		\label{tab:energia}}
\end{table}



\begin{figure} [!b]
	\centering
	\includegraphics[width=\textwidth, keepaspectratio]{Grafici_Tesi/Rigidita/deltaE-Eres_3.png}
	\caption{Le matrici $\Delta E_{SiC} - E_{CsI}$ considerando uno spessore del substrato morto pari a 10~$\mu$m.} \label{fig:deltaE_ERes_rigidita}
\end{figure}
