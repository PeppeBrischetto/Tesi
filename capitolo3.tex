



Al fine di valutare se la scelta della tecnologia SiC-CsI può soddisfare le esigenze di NUMEN è stata implementata una simulazione Monte Carlo sulla piattaforma GEANT4.
In questo capitolo vengono esposte le principali assunzioni e vengono presentati i risultati.
(\textcolor{red}{chiedere se geant4 va scritto in maiuscoletto})


%Le simulazioni giocano un ruolo fondamentale nella fisica.

%In fisica, come in altre scienze, le simulazioni giocano un ruolo fondamentale, in quanto permettono di studiare la risposta di sistemi complessi tenendo sotto controllo alcuni dei suoi gradi di libertà.

\section{\iflanguage{italian}{Le simulazioni computerizzate e i metodi Monte Carlo}{Computer simulations and Monte-Carlo methods}}


In fisica, come in altre scienze, le simulazioni computerizzate giocano un ruolo fondamentale, in quanto permettono di affrontare lo studio di sistemi che sarebbero difficilmente trattabili utilizzando tecniche teoriche o sperimentali~``classiche'';
spesso, infatti, tali approcci possono presentare problematicità legate alla complessità del sistema, al tempo necessario per lo sviluppo e l'analisi, ai costi per la realizzazione di prototipi.
Introdotte negli anni Trenta grazie all'apporto di prestigiosi scienziati come von Neumann, Ulam e Fermi, il loro progresso è stato parallelo a quello dei computer, arrivando oggi ad essere uno strumento imprescindibile in molti esperimenti.
Esse forniscono una diversa prospettiva con cui guardare alla realtà, diventando in alcuni casi una base teorica da cui partire per l'interpretazione dei risultati sperimentali, oppure in altre situazioni producendo dati ``sperimentali'' con cui mettere al vaglio le teorie.


Tra i diversi metodi di simulazione computerizzata, particolare importanza hanno assunto i cosiddetti \emph{metodi Monte Carlo}~\cite{metropolis:jasa49}, il cui nome fu coniato da Metropolis ispirandosi al casinò omonimo.
%Tali metodi utilizzano la generazione di sequenze di numeri \emph{pseudo-casuali} per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà, 
%laddove i numeri pseudo-casuali sono dei numeri prodotti in modo deterministico ma con proprietà statistiche simili a quelle dei numeri casuali.
%
Il numero di problemi che al giorno d'oggi vengono studiati utilizzando questa tecnica è enorme, annoverando campi di ricerca estremamente diversi, che vanno dalla fisica nucleare alla fisica medica, dalla meccanica statistica alla sociofisica, dall'economia alla biologia.
%Darne una definizione comprensiva di tutte le aree di interesse è un compito difficile e sostanzialmente inutile.
%
% ***** QUESTO NON ERA MALE
%Sebbene darne una definizione comprensiva di tutte le aree di interesse sia un compito difficile, in generale è possibile dire che i metodi Monte Carlo utilizzano la generazione di numeri casuali per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà accoppiati.
%
%
Sebbene darne una definizione comprensiva di tutte le aree di interesse sia un compito difficile, in generale è possibile dire che i metodi Monte Carlo sono dei metodi numerici di risoluzione di equazioni o di calcolo di integrali basati sulla generazione di numeri casuali.
%I metodi Monte Carlo utilizzano la generazione di numeri casuali per simulare le fluttuazioni statistiche di un sistema con un numero elevato di gradi di libertà.
Il generico metodo si compone principalmente di quattro fasi:
\begin{itemize}
	\item generazione di una sequenza di numeri casuali;
	\item calcolo delle variabili di input sulla base della sequenza estratta;
	\item determinazione delle variabili di output utilizzando le variabili di input calcolate;
	\item ripetizione dei punti precedenti e analisi critica dei risultati.
\end{itemize}



%Dal momento che i metodi Monte Carlo dipendono fortemente dalla produzione veloce ed efficiente di flussi di numeri casuali, si preferisce generare le sequenze di numeri via software, piuttosto che leggerli da tavole ad hoc.
%Tuttavia, poiché tali algoritmi sono, in realtà, deterministici, 
%In realtà, dal momento che, per ragioni di velocità ed efficienza, tali sequenze sono prodotte via software, i numeri sono \emph{pseudo-casuali}
%Per risolvere un problema complesso è necessaria una sequenza molto grande di numeri casuali, i quali devono essere indipendenti fra loro.
Affinché il metodo si dimostri efficace, è essenziale che la sequenza di numeri sia quanto più possibile casuale.
Dunque, proprio la casualità con cui vengono prodotti tali numeri rappresenta il punto più delicato del metodo e, forse, il suo limite più grande; infatti, per ragioni di velocità ed efficienza i numeri vengono generati via software, invece di basarsi su processi fisici realmente casuali.
%Tuttavia, dal momento che tali algoritmi sono inevitabilmente deterministici, le sequenze di numeri sono, in realtà, \emph{pseudo-casuali}, ovvero presentano delle proprietà statistiche simili a quelle dei numeri casuali. 
Tuttavia, dal momento che tali algoritmi sono inevitabilmente deterministici, ogni numero della sequenza è univocamente calcolato a partire dal suo predecessore. 
Quindi, le sequenze di numeri sono, in realtà, \emph{pseudo-casuali}, ovvero presentano delle proprietà statistiche analoghe a quelle delle sequenze di numeri casuali, ma sono prodotte in modo deterministico. 
Per questo motivo, una successione di numeri pseudo-casuali non può avere elementi infinitamente diversi, in quanto, prima o poi, cominceranno a ripetersi.

Negli ultimi trent'anni l'importanza delle simulazioni basate su metodi Monte Carlo è cresciuta senza soluzione di continuità. 
%Uno dei motivi di tale successo deriva in quanto al crescere della complessità del problema tale tecnica risulta superiore rispetto agli approcci analitici in termini di tempo necessario per la 
%Uno dei motivi di tale successo deriva dalla maggiore efficacia di queste tecniche rispetto agli approcci analitici nella risoluzione di problemi caratterizzati da alta complessità;
%ad esempio, valutando l'efficacia di un metodo in termini del tempo necessario per risolvere un problema, al crescere della complessità risulta che tale tempo cresce più lentamente per i metodi Monte Carlo in confronto ai metodi analitici.
%come illustrato in Figura~\ref{fig:monte_carlo}, il tempo necessario 
%Uno dei motivi di tale successo deriva dalla grande efficacia di queste tecniche nella risoluzione di problemi altamente complessi;
Una delle ragioni di tale successo deriva dalla grande efficacia di queste tecniche nell'affrontare lo studio di sistemi con un numero elevato di gradi di libertà accoppiati; 
ad esempio, è possibile dimostrare che, al crescere della complessità del problema, i metodi Monte Carlo richiedono meno tempo per giungere alla soluzione rispetto alle tecniche analitiche o deterministiche, come mostrato in Figura~\ref{fig:monte_carlo}.


\begin{figure} [!t]
	\centering
	\includegraphics[scale=0.7]{Grafici/monte_carlo_vs_analytic2.png}
	\caption{Confronto fra il tempo necessario per la risoluzione di un problema con un metodo analitico-deterministico e con un metodo Monte Carlo, al variare della complessità del problema.} \label{fig:monte_carlo}
\end{figure}


%Nel campo della fisica, i metodi Monte Carlo sono spesso utilizzati per 
%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui l'elevata complessità degli apparati di rivelazione necessitava di uno strumento per decidere le specifiche in fase di progettazione.


%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui la crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
%
% ***** PRIMA AVEVO MESSO QUESTA
%Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui si comprese che tali metodi offrivano la possibilità di seguire la traccia delle particelle e simulare le loro interazioni con la materia.
%
Un notevole impulso allo sviluppo dei metodi Monte Carlo è provenuto dalla fisica delle alte energie, in cui si comprese che tali metodi, offrendo la possibilità di seguire la traccia delle particelle e simulare le loro interazioni con la materia, potevano essere impiegati sia per la progettazione dei rivelatori sia per lo studio della loro risposta nelle condizioni sperimentali di interesse.
In questo contesto nacque il codice \emph{GEANT}, di cui nella sezione successiva si espongono le principali caratteristiche.





\section{\iflanguage{italian}{La piattaforma \textsc{Geant4}}{\textsc{Geant4} toolkit}}

%\section{\textsc{Geant4}}

La piattaforma GEANT, il cui nome deriva da \emph{GEometry ANd Tracking}, fu sviluppata nel 1974 al CERN di Ginevra allo scopo di simulare l'interazione di particelle elementari ad alta energia con i rivelatori.
%Questa prima versione consentiva di simulare il trasporto di un numero ristretto di particelle 
%In questa prima versione era possibile simulare soltanto un numero ristretto di particelle
In questa prima versione era possibile considerare soltanto un numero ristretto di particelle e forme geometriche semplici. 
Nel 1982 venne distribuito GEANT3, scritto in FORTRAN e nettamente potenziato rispetto al suo predecessore; infatti, si potevano simulare apparati sperimentali grandi e sofisticati e fasci di particelle molto intensi ed energetici.
Tuttavia, il codice presentava una struttura molto complessa, che rendeva difficile l'introduzione di nuove caratteristiche o la ricerca di errori.
%the simulation software geant4, which means \emph{geometry and tracking}, is a toolkit based on
%Fu così che si arrivò al 1998, anno dell'uscita dell'ultima versione del codice, chiamata \geant, interamente basata sul linguaggio C++.
%La crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
%
%%Fu così che nel 1998, grazie alla collaborazione di oltre 40 istituti internazionali, venne pubblicata l'ultima versione del codice, chiamata \geant.
D'altro canto, la crescente necessità di simulare complessi sistemi di rivelazione spingeva per la realizzazione di software sempre più performanti e robusti.
Fu così che nel 1998, grazie alla collaborazione di oltre 40~istituti internazionali, venne pubblicata l'ultima versione del codice, chiamata \geant.
Essa è interamente basata sul linguaggio C++, traendo vantaggio, dunque, da tutte le potenzialità offerte da una tecnologia orientata agli oggetti, come ad esempio la modularità e la compattezza.
% oppure il polimorfismo
%Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto comprende un insieme di librerie software che l'utente può selezionare a seconda delle proprie esigenze per creare un'applicazione specifica.

Oggi \geant{} consente di simulare l'interazione con la materia di tutte le particelle note, in un range energetico che va da pochi~eV fino ai~TeV.
%
%La sua notevole duttilità lo ha reso uno strumento 
Grazie alla sua notevole duttilità, sono innumerevoli gli esperimenti che si avvalgono di questo strumento e la sua area d'applicazione va dalla fisica delle alte energie, agli studi nucleari, alle applicazioni in campo medico, all'astrofisica.
Il codice è, inoltre, open-source e viene periodicamente aggiornato dalla collaborazione. 
Dal momento che la documentazione su \geant{} è ampia e dettagliata\footnote{Si veda, ad esempio, \url{www.geant4.cern.ch}}, nel prosieguo vengono presentati soltanto gli aspetti utili alla comprensione della simulazione svolta per questo lavoro di tesi.  



\subsection{\iflanguage{italian}{La struttura di \textsc{Geant4}}{\textsc{Geant4} structure}}

%Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto comprende un insieme di librerie software che l'utente può selezionare a seconda delle proprie esigenze per creare un'applicazione specifica.
Il modo più corretto di definire \geant{} è \emph{toolkit}, ovvero ``cassetta per gli attrezzi'', in quanto è costituito da un insieme di librerie software che, a seconda delle esigenze, possono essere selezionate per creare un'applicazione specifica.
L'utente deve, quindi, scrivere la sua applicazione, definendo tutti i parametri rilevanti: alcuni devono essere inseriti in modo obbligatorio, altri possono essere aggiunti facoltativamente.
%\geant{} offre numerose funzionalità:

%Ogni simulazione si compone dei seguenti aspetti: 
Nella progettazione e nella realizzazione del software, tutti gli aspetti fondamentali di un processo di simulazione sono stati inclusi:
\begin{itemize}
	\item la geometria del sistema, specificando forma, dimensione e posizione dei vari oggetti;
	\item i materiali utilizzati;
	\item la sorgente delle particelle, di cui si definisce la posizione, l'energia, la distribuzione angolare e tutte le altre caratteristiche rilevanti;
	\item i processi fisici di interazione per la modellizzazione  del comportamento delle particelle;
	%\item il tracciamento delle particelle, che può essere calcolato anche passo dopo passo, consentendo di estrarre ad ogni step informazioni legate alla particella, come ad esempio energia e posizione;
	\item il tracciamento delle particelle attraverso materiali ed, eventualmente, campi elettromagnetici esterni;
	%\item la sensitività di un rivelatore e la sua risposta;
	\item la definizione di elementi sensibili, che simulano la risposta del rivelatore;
	\item la visualizzazione tridimensionale degli oggetti simulati e delle tracce delle particelle;
	\item la generazione di dati, i quali possono essere memorizzati per una successiva analisi.
\end{itemize}


%Ciascuno degli aspetti elencati corrisponde ad una determinata \emph{classe} o \emph{categoria}, che, agendo in modo indipendente l'una dall'altra, danno al software una struttura modulare.

Gli aspetti elencati corrispondono in \geant{} a determinate \emph{classi} o \emph{categorie}, che, agendo in modo indipendente l'una dall'altra, danno al software una struttura modulare.
%Esse sono state concepite per essere facilmente estendibili o modificabili dall'utente, seguendo la logica tipica dei linguaggi orientati agli oggetti;
Esse sono state concepite per essere facilmente estendibili o modificabili, seguendo la logica tipica dei linguaggi orientati agli oggetti; infatti, grazie alla proprietà del \emph{polimorfismo}, l'utente può fornire un'implementazione alternativa delle funzioni presenti in una categoria (\textcolor{red}{provo a spiegarlo meglio introducendo le classi di base e le classi derivate?}).
%Di tutte le classi messe a disposizione, \geant{} richiede obbligatoriamente l'implementazione e l'istanziazione di tre, ovvero 
%\geant mette a disposizione un grande numero di classi, le quali sono state  concepite per essere facilmente estendibili o modificabili dall'utente, seguendo la logica tipica dei linguaggi orientati agli oggetti.
%L'implementazione e l'istanziazione di queste classi sono obbligatorie in tre casi, ovvero
%\geant{} mette a disposizione un grande numero di classi, ma per tre di loro l'implementazione e l'istanziazione sono obbligatorie.
\geant{} mette a disposizione un grande numero di classi, richiedendo obbligatoriamente l'implementazione e l'istanziazione per tre di loro: 
\begin{itemize}
	\item la classe dedicata alla definizione della geometria e dei materiali;
	\item la classe prevista per la definizione delle particelle, dei processi fisici e dei parametri di cut-off;
	\item la classe rivolta alla generazione delle particelle primarie.
\end{itemize}


%Altre classi

Le altre classi sono, invece, opzionali e, a seconda delle esigenze, l'utente può modificarne il comportamento di default definendo la propria implementazione; 
%ad esempio, ai fini di questo lavoro è stato necessario personalizzare la classe che rappresenta ogni ``passo'' della traccia della particella, facendo in modo che ad ogni step venisse estratta l'informazione sulla perdita di energia e sulla posizione.
%
ad esempio, in \geant{} esiste una classe che rappresenta ogni ``passo'' (più propriamente chiamato \emph{step}) della traccia della particella.
%, laddove per passo possiamo immaginare un segmento che compone la traiettoria.
L'utente può personalizzare tale classe, facendo in modo che ad ogni step vengano estratte alcune informazioni, come la posizione e l'energia della particella.
%In \geant{} la traccia della particella è divisa in \emph{step}, che, per comodità, possiamo immaginare come dei segmenti.
%Grazie ad un'apposita classe, è possibile accedere a diverse informazioni legate a tale step, come estremi 


\section{\iflanguage{italian}{Gli aspetti principali della simulazione}{Simulation main aspects}}

%La simulazione implementata per questo lavoro di tesi considera una matrice di telescopi SiC-CsI.
%Allo scopo di valutare le prestazioni di PID
Nell'ambito del presente lavoro di tesi è stata realizzata un'applicazione in \geant{} per simulare la risposta di un sistema di telescopi SiC-CsI agli ioni di interesse per il progetto NUMEN.
Nel seguito di questa sezione vengono illustrate nel dettaglio le caratteristiche di tale simulazione.




\subsection{\iflanguage{italian}{La geometria e i materiali}{Geometry and materials}}

Considerando un sistema di riferimento in cui l'asse $z$ è individuato dalla direzione di propagazione delle particelle, i telescopi sono fra loro separati di 2~mm lungo la direzione $x$ e di 1~mm lungo la direzione $y$.

%Ciascun telescopio è formato da tre parti: il volume attivo del rivelatore al SiC, il substrato morto dello stesso rivelatore e il cristallo allo CsI.
Ciascun telescopio è formato da due componenti, il rivelatore al carburo di silicio (SiC) e il cristallo allo ioduro di cesio (CsI), le quali sono poste a contatto.
Per tenere in considerazione il substrato morto del rivelatore al SiC, tale componente è, a sua volta, costituita da due parti: il volume attivo e il substrato morto.
%In accordo con le 
%
%Un importante aspetto della simulazione riguarda lo spessore dei rivelatori.


%Dal momento che nuovi sviluppi tecnologici hanno reso possibile la rimozione quasi totale del substrato, sono state svolte anche delle simulazioni in cui il suo spessore era ridotto a 10~$\mu$m. 
%Per quanto riguarda il cristallo di CsI, lo spessore è stato posto uguale a 1~cm.


%Poiché uno degli obiettivi di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità,  sono stati considerati diversi valori per le dimensioni trasversali; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.
%Poiché uno degli obiettivi di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità,  per le dimensioni trasversali dei telescopi sono stati presi in esame diversi valori; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.
Poiché uno degli obiettivi di questo lavoro consisteva nella ricerca delle migliori condizioni di granularità, sono state condotte diverse simulazioni al variare delle dimensioni trasversali dei telescopi; in particolare, sulla base degli attuali limiti imposti dal processo di produzione dei rivelatori al SiC, sono state simulate aree sensibili di $1 \times 1$, $1.5 \times 1.5$ e $2 \times 2$~cm\ap{2}.




%Lo spessore del primo è di 100~$\mu$m, mentre quello del secondo è di 350~$\mu$m.
%Un altro aspetto importante della simulazione riguarda lo spessore del rivelatore al SiC; infatti, sebbene la collaborazione abbia suggerito 
%Per quanto riguarda lo spessore dei due stadi del telescopio, la collaborazione aveva individuato come probabile soluzione l'utilizzo di rivelatori al SiC da 100~$\mu$m e di cristalli allo CsI di 1~cm. 

%Lo standard tecnologico attuale prevede che un rivelatore al SiC di tale spessore abbia un substrato morto spesso 350~$\mu$m.
Per quanto riguarda lo spessore dei due stadi del telescopio, in accordo con la soluzione individuata dalla collaborazione, sono stati simulati rivelatori al~SiC da 100~$\mu$m e cristalli allo CsI da 1~cm, mentre per il substrato morto si è considerato un valore di 350~$\mu$m.
%Gli spessori tenuti in considerazione erano di 100~$\mu$m per il rivelatore al SiC, di 350~$\mu$m per il substrato morto e di 1~cm per il cristallo allo CsI.
Tuttavia, dal momento che nuovi sviluppi tecnologici hanno reso possibile la rimozione quasi totale degli strati morti, si è esaminato anche il caso in cui lo spessore del substrato era ridotto a 10~$\mu$m. 
È stato, dunque, effettuato un confronto tra le due diverse condizioni, allo scopo di valutare le conseguenze sulle capacità di~PID.





%Sebbene il muro di telescopi comprenderà oltre 1000 
%La simulazione ha considerato un unico modulo di $2 \times 5$ rivelatore.
Dal momento che per gli scopi di questo lavoro non era necessario includere l'intero muro di oltre 1000 telescopi, tutte le simulazioni svolte hanno preso in esame una matrice $3 \times 3$ di elementi.
In Figura~ è mostrato l'aspetto assunto da tale matrice nella simulazione \geant. (\textcolor{red}{sarebbe meglio dire che ho preso in considerazione un modulo $2 \times 5$?})
%In Figura~ è possibile vedere la realizzazione grafica di \geant{} di un modulo $2 \times 5$ del sistema di rivelazione.




\subsection{\iflanguage{italian}{La generazione delle particelle primarie}{Primary particles generation}}

%Le particelle primarie simulate comprendono tre degli ioni di maggiore interesse per NUMEN, ovvero \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne}. 
%In alcune simulazioni sono stati coinvolti anche altri isotopi di tali specie nucleari, 
Le particelle primarie simulate comprendono tre degli ioni di maggiore interesse per NUMEN, ovvero \ce{^{18}O}, \ce{^{18}F} e \ce{^{18}Ne}, coinvolgendo in alcune simulazioni anche altri isotopi di tali specie nucleari (\textcolor{red}{dico esplicitamente quali?}).


In ciascun evento, la particella primaria è generata in modo casuale sulla faccia frontale di un rivelatore al SiC, con una direzione estratta casualmente all'interno di un angolo corrispondente ad un cono con un'apertura di 20\textdegree{}. 


%Allo scopo di coprire un ampio range energetico, realisticamente significativo per NUMEN, le particelle primarie hanno un'energia scelta casualmente fra 500 e 1000~MeV.
Allo scopo di valutare la capacità di PID in un ampio range energetico, realisticamente significativo per NUMEN, sono state simulate particelle primarie con un'energia scelta casualmente fra 500 e 1000~MeV.
%Dal momento che l'apparato sperimentale si incardina sulle proprietà dello spettrometro magnetico MAGNEX, 

Inoltre, dal momento che negli spettrometri magnetici la posizione di una particella al piano focale è correlata alla sua energia, in accordo con la nota relazione
\begin{equation} \label{eq:legge_spettrometri}
B  \rho \, = \,  \frac{p}{q}
\end{equation}
laddove $B$ è il campo magnetico, mentre $\rho$, $p$ e $q$ sono, rispettivamente, il raggio di curvatura, l'impulso e la carica della particella, alcune simulazioni sono state svolte tenendo fissato il $B \rho$ degli ioni primari.
(\textcolor{red}{secondo lei è meglio inserire la relazione del $B \rho $ nel cap 1?})


\subsection{\iflanguage{italian}{I processi fisici}{Physics processes}}


Affinché la simulazione possa riprodurre con la maggiore accuratezza possibile i risultati sperimentali reali, è di cruciale importanza la scelta dei processi fisici da considerare allo scopo di definire il comportamento delle particelle.
Per gli scopi di questo lavoro, in una prima fase sono state prese in esame soltanto le interazioni elettromagnetiche, oltre ai processi di decadimento e di decadimento radioattivo, in quanto sufficienti a separare i luoghi degli ioni nelle matrici $\Delta E - E$.
Successivamente, sono state aggiunte anche le interazioni adroniche, incorporando, dunque, processi di scattering elastico e inelastico e meccanismi di reazioni nucleari.

%Non sono state modificate le impostazioni di default di
Una delle componenti fondamentali di \geant{} riguarda la scelta dei parametri di cut-off; infatti, è possibile stabilire una soglia, in range o in energia, al di sotto delle quale non viene generata la particella secondaria.
Dal momento che ai fini di questo lavoro una modifica dei parametri di cut-off non avrebbe portato a significativi cambiamenti dei risultati, si è scelto di mantenerne le impostazioni di default.



\subsection{\iflanguage{italian}{Step della particella}{Particle step}}

%In \geant{} la traccia della particella è divisa in \emph{step}, che, per comodità, possiamo immaginare come dei segmenti.
%Grazie ad un'apposita classe, è possibile accedere a diverse informazioni legate a tale step.
Come anticipato nella sezione precedente, in \geant{} è possibile dare la propria implementazione della classe che rappresenta gli step della particella.
Dal momento che, ai fini di questo lavoro, si volevano valutare le conseguenze sulla PID causate dagli effetti di bordo dei rivelatori, era necessario sapere punto per punto la posizione dello ione. 
Dunque, è stato modificato il comportamento di default di questa classe, affinché ad ogni step si conoscessero gli estremi di tale step e il deposito di energia.
(\textcolor{red}{Spiego anche che veniva estratto un punto casuale fra gli estremi dello step?})








\subsection{\iflanguage{italian}{Elaborazione post-simulazione}{Post-simulation processing}}

I dati prodotti dalla simulazione, scritti in un tree, sono stati elaborati in una macro di ROOT~\cite{brun:nima97}, in cui vengono aggiunte alcune caratteristiche tipiche dei rivelatori reali.
%In primo luogo, ciascun deposito di energia viene pesato con una funzione di r
%In primo luogo, dal momento che 
%
In primo luogo, a causa del processo di produzione, i rivelatori al SiC presentano nel volume sensibile un bordo esterno completamente inattivo, in cui la carica generata per ionizzazione non viene raccolta, ed una regione di transizione, dove la carica prodotta viene raccolta soltanto in parte.
Secondo le misurazioni effettuate, la zona totalmente morta ha una lunghezza di circa 10~$\mu$m, mentre la regione di transizione ha un'estensione di 2~$\mu$m. 
%Nella macro si è tenuto conto di tali \emph{effetti di bordo} pesando ciascun deposito di energia con una \emph{funzione di risposta} lineare, che nel caso unidimensionale sarebbe così definita: 
%\begin{equation}
%f(x) =
%\begin{cases}
%1        & \quad  x<a \\
%\alpha x & \quad  b<x<a\\
%0        & \quad  x>b
%\end{cases}
%\end{equation}
%
Nella macro si è tenuto conto di tali \emph{effetti di bordo} pesando ciascun deposito di energia con una \emph{funzione di risposta} così definita: nella zona interamente attiva era pari ad uno, nella regione di transizione decresceva linearmente e nella zona del tutto inattiva aveva valore nullo (\textcolor{red}{Secondo lei è più chiaro se metto la formula del caso unidimensionale?}).

%Nella macro, inoltre, sommando le diverse perdite di energia, per ogni evento veniva ricostruito il deposito energetico totale nel rivelatore al SiC e nel cristallo allo CsI.
Nella macro, inoltre, sommando le diverse perdite di energia, per ogni evento veniva ricostruito il deposito energetico totale, sia per il rivelatore al SiC sia per il cristallo allo CsI.
Mettendo insieme i depositi di energia di tutti gli eventi, si riproducevano gli spettri energetici degli ioni nei due stadi del telescopio.
A questo livello, soltanto le fluttuazioni statistiche legate alla ionizzazione erano tenute in considerazione.
Dunque, al fine di riprodurre le risoluzioni energetiche tipiche dei rivelatori in esame, lo spettro energetico è stato ``allargato'' campionando ciascun deposito di energia con una distribuzione gaussiana, la cui espressione è
%\begin{equation}
%	f(E) = A \, \mbox{e}^{- \frac{E - E_0}{2 {\sigma}^2}}
%\end{equation}
\begin{equation}
	f(E, E_0, \sigma) = A \, \exp \left( \frac{E - E_0}{2 {\sigma}^2} \right)
\end{equation}
dove $A$ è una costante di normalizzazione, $E_0$ è il valore originario del deposito di energia, $E$ è il valore dopo il campionamento e $\sigma$ è la deviazione standard.
Di tale distribuzione, noto il valore medio $E_0$, bisognava scegliere la $\sigma$ in modo tale che la risoluzione energetica ricavata dalla simulazione fosse confrontabile con quella sperimentale.
%Dal momento che la risoluzione energetica è generalmente espressa come la somma in quadratura di un termine legato alle fluttuazioni statistiche del numero dei portatori e di uno dovuto al rumore elettronico, nella macro si è parametrizzata la $\sigma$ nel modo seguente
La risoluzione energetica è generalmente espressa come la somma in quadratura di un termine legato alle fluttuazioni statistiche del numero dei portatori, proporzionale a $E^{-1/2}$, e di uno dovuto al rumore elettronico, proporzionale a $E^{-1}$~\cite{knoll:10}.
Dunque, dal momento che la $\sigma$ può essere posta in relazione alla risoluzione energetica $R$ dalla seguente relazione
\begin{equation}
	R \,  = \, \frac{\mbox{FWHM}}{E} \, = \, \frac{2.35 \, \sigma}{E}
\end{equation}
nella macro si è parametrizzata la deviazione standard nel modo seguente
\begin{equation}
\sigma = \sqrt{a + b \, E}
\end{equation}
laddove $a$ e $b$ sono due costanti.
%che assumono valori diversi a seconda che si consideri il rivelatore al SiC o il cristallo allo CsI. 
Nella somma al secondo membro, il primo addendo corrisponde al termine legato al rumore elettronico, mentre il secondo rappresenta quello causato dalle fluttuazioni del numero di portatori.
%
%
%Ricordando che la FWHM è legata alla $\sigma$ dalla relazione
%\begin{equation}
%\mbox{FWHM} = 2.35 \, \sigma
%\end{equation}
%la deviazione standard risulta collegata alla risoluzione energetica.
%Dal momento che quest'ultima è generalmente determinata dalla somma in quadratura di un termine legato all
Scegliendo opportuni valori per $a$ e $b$, si è assunta per il rivelatore al SiC una risoluzione energetica dello 0.8\% FWHM a 19.4~MeV, mentre per il rivelatore allo CsI dell'1.8\% FWHM a 850~MeV (\textcolor{red}{Devo specificare i valori di a e b scelti nei due casi?}).







%\clearpage


\section{\iflanguage{italian}{I risultati}{Results}}


